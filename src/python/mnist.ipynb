{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "batch_size = 100\n",
    "data_path='../data/mnist'\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))\n",
    "            ])\n",
    "# transform = transforms.Compose([\n",
    "#             transforms.Resize((28, 28)),\n",
    "#             transforms.ToTensor(),\n",
    "#             ])\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "num_inputs = 28*28\n",
    "num_hidden = 256\n",
    "num_outputs = 10\n",
    "\n",
    "# Temporal Dynamics\n",
    "num_steps = 20\n",
    "beta = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        spike_input = spikegen.rate(x, num_steps=num_steps) # Generate spike trains\n",
    "        # print(\"spike_input\")\n",
    "        # print(spike_input.shape)\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # print(spike_input[step].sum(axis=-1))\n",
    "            # print(spike_input[step].shape)\n",
    "            cur1 = self.fc1(spike_input[step])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            # print(\"spk1\")\n",
    "            # print(spk1.shape)\n",
    "            # print(spk1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            # print(cur1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            # print(\"spk2\")\n",
    "            # print(spk2.shape)\n",
    "            # print(spk2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0\n",
      "Train Set Loss: 47.33\n",
      "Test Set Loss: 46.41\n",
      "Train set accuracy for a single minibatch: 23.00%\n",
      "Test set accuracy for a single minibatch: 16.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 50\n",
      "Train Set Loss: 14.90\n",
      "Test Set Loss: 11.93\n",
      "Train set accuracy for a single minibatch: 84.00%\n",
      "Test set accuracy for a single minibatch: 90.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 100\n",
      "Train Set Loss: 8.71\n",
      "Test Set Loss: 10.67\n",
      "Train set accuracy for a single minibatch: 91.00%\n",
      "Test set accuracy for a single minibatch: 94.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 150\n",
      "Train Set Loss: 7.47\n",
      "Test Set Loss: 5.93\n",
      "Train set accuracy for a single minibatch: 92.00%\n",
      "Test set accuracy for a single minibatch: 94.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 200\n",
      "Train Set Loss: 10.94\n",
      "Test Set Loss: 9.19\n",
      "Train set accuracy for a single minibatch: 91.00%\n",
      "Test set accuracy for a single minibatch: 87.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 250\n",
      "Train Set Loss: 6.14\n",
      "Test Set Loss: 10.06\n",
      "Train set accuracy for a single minibatch: 95.00%\n",
      "Test set accuracy for a single minibatch: 89.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 300\n",
      "Train Set Loss: 6.44\n",
      "Test Set Loss: 7.86\n",
      "Train set accuracy for a single minibatch: 94.00%\n",
      "Test set accuracy for a single minibatch: 88.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 350\n",
      "Train Set Loss: 6.99\n",
      "Test Set Loss: 5.32\n",
      "Train set accuracy for a single minibatch: 93.00%\n",
      "Test set accuracy for a single minibatch: 91.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 400\n",
      "Train Set Loss: 9.19\n",
      "Test Set Loss: 6.89\n",
      "Train set accuracy for a single minibatch: 94.00%\n",
      "Test set accuracy for a single minibatch: 92.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 450\n",
      "Train Set Loss: 4.43\n",
      "Test Set Loss: 6.48\n",
      "Train set accuracy for a single minibatch: 94.00%\n",
      "Test set accuracy for a single minibatch: 94.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 500\n",
      "Train Set Loss: 4.19\n",
      "Test Set Loss: 7.60\n",
      "Train set accuracy for a single minibatch: 96.00%\n",
      "Test set accuracy for a single minibatch: 89.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 550\n",
      "Train Set Loss: 9.09\n",
      "Test Set Loss: 3.94\n",
      "Train set accuracy for a single minibatch: 94.00%\n",
      "Test set accuracy for a single minibatch: 95.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output, _ = net(data.view(batch_size, -1))\n",
    "    _, idx = output.sum(dim=0).max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    if train:\n",
    "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer():\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "    print_batch_accuracy(data, targets, train=True)\n",
    "    print_batch_accuracy(test_data, test_targets, train=False)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "        # print(mem_rec.shape)\n",
    "        # print(mem_rec)\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        for step in range(num_steps):\n",
    "            loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk, test_mem = net(test_data.view(batch_size, -1))\n",
    "\n",
    "            # Test set loss\n",
    "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "            for step in range(num_steps):\n",
    "                test_loss += loss(test_mem[step], test_targets)\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "\n",
    "            # Print train/test loss/accuracy\n",
    "            if counter % 50 == 0:\n",
    "                train_printer()\n",
    "            counter += 1\n",
    "            iter_counter +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correctly classified test set images: 9369/10000\n",
      "Test Set Accuracy: 93.69%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# drop_last switched to False to keep all samples\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "  net.eval()\n",
    "  for data, targets in test_loader:\n",
    "    data = data.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    test_spk, _ = net(data.view(data.size(0), -1))\n",
    "\n",
    "    # calculate total accuracy\n",
    "    _, predicted = test_spk.sum(dim=0).max(1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets).sum().item()\n",
    "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
    "print(f\"Test Set Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for CSV output.\n",
    "spike_save_path = \"mnist_input_spikes.csv\"\n",
    "label_save_path = \"mnist_labels.csv\"\n",
    "\n",
    "all_spikes = []\n",
    "all_labels = []\n",
    "\n",
    "# Loop over your test_loader.\n",
    "for data, targets in test_loader:\n",
    "    data = data.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # Convert images to spike trains.\n",
    "    # Assume spike_data has shape (num_steps, batch_size, vector_length)\n",
    "    spike_data = spikegen.rate(data.view(batch_size, -1), num_steps=num_steps).cpu().numpy()\n",
    "    # Remove the batch dimension (assumed to be 1)\n",
    "    spike_data = np.squeeze(spike_data, axis=1)  # Now shape is (num_steps, vector_length)\n",
    "    all_spikes.append(spike_data)\n",
    "    \n",
    "    # For labels, assume each batch yields one label.\n",
    "    all_labels.append(targets.cpu().numpy())\n",
    "\n",
    "# Concatenate all batches along the time dimension.\n",
    "all_spikes = np.concatenate(all_spikes, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Save spike data and labels as CSV.\n",
    "# The CSV file for spikes will have (total_time_steps x vector_length) entries.\n",
    "np.savetxt(spike_save_path, all_spikes.astype(np.int8), delimiter=\",\", fmt=\"%d\")\n",
    "np.savetxt(label_save_path, all_labels.astype(np.int8), delimiter=\",\", fmt=\"%d\")\n",
    "\n",
    "print(\"Spike data and labels saved as CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"weights_fc1.txt\", net.fc1.weight.detach().numpy())\n",
    "np.savetxt(\"weights_fc2.txt\", net.fc2.weight.detach().numpy())\n",
    "np.savetxt(\"bias_fc1.txt\", net.fc1.bias.detach().numpy())\n",
    "np.savetxt(\"bias_fc2.txt\", net.fc2.bias.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, label in test_loader:\n",
    "    break\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =  data[0,0,:,:] * 255\n",
    "f = d.cpu().numpy()\n",
    "np.savetxt(\"input_image.txt\", f.flatten())\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# get the weights and bias of every layer in the network and put it in one array\n",
    "w = net.fc1.weight.detach().cpu().numpy()\n",
    "b = net.fc1.bias.detach().cpu().numpy()\n",
    "w = np.concatenate((w.flatten(), b.flatten()), axis=0)\n",
    "w2 = net.fc2.weight.detach().cpu().numpy()\n",
    "b2 = net.fc2.bias.detach().cpu().numpy()\n",
    "w2 = np.concatenate((w2.flatten(), b2.flatten()), axis=0)\n",
    "a = np.concatenate((w, w2), axis=0)\n",
    "\n",
    "# find absolute max and min of the weights and bias\n",
    "max_val = np.max(a)\n",
    "min_val = np.min(a)\n",
    "print(\"Max weight: \", max_val)\n",
    "print(\"Min weight: \", min_val)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Weight Distribution of fc1 Layer\")\n",
    "plt.xlabel(\"Weight Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(False)\n",
    "\n",
    "plt.hist(a.flatten(), bins=256, range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q07_SCALE = 128.0\n",
    "Q07_MAX_FLOAT = 127 / 128.0    # 0.9921875\n",
    "Q07_MIN_FLOAT = -1.0\n",
    "Q07_MAX_INT8 = 127\n",
    "Q07_MIN_INT8 = -128\n",
    "\n",
    "def quantize_q07(x: float) -> int:\n",
    "    if x > Q07_MAX_FLOAT:\n",
    "        x = Q07_MAX_FLOAT\n",
    "    elif x < Q07_MIN_FLOAT:\n",
    "        x = Q07_MIN_FLOAT\n",
    "\n",
    "    scaled = int(x * Q07_SCALE + (0.5 if x >= 0 else -0.5))\n",
    "\n",
    "    if scaled > Q07_MAX_INT8:\n",
    "        scaled = Q07_MAX_INT8\n",
    "    elif scaled < Q07_MIN_INT8:\n",
    "        scaled = Q07_MIN_INT8\n",
    "\n",
    "    return np.int8(scaled)\n",
    "\n",
    "def quantize_tensor_q07(tensor: torch.Tensor):\n",
    "    tensor_np = tensor.detach().cpu().numpy()\n",
    "    quantized = np.vectorize(quantize_q07)(tensor_np).astype(np.int8)\n",
    "    return quantized\n",
    "\n",
    "def format_c_array(var_name: str, array: np.ndarray) -> str:\n",
    "    shape = array.shape\n",
    "    dims = ''.join([f\"[{d}]\" for d in shape])\n",
    "    result = f\"const int8_t {var_name}{dims} = {{\\n\"\n",
    "\n",
    "    if array.ndim == 1:\n",
    "        result += \"    { \" + ', '.join(str(v) for v in array) + \" }\\n\"\n",
    "    elif array.ndim == 2:\n",
    "        for row in array:\n",
    "            result += \"    { \" + ', '.join(str(v) for v in row) + \" },\\n\"\n",
    "    elif array.ndim == 3:\n",
    "        for mat in array:\n",
    "            result += \"    {\\n\"\n",
    "            for row in mat:\n",
    "                result += \"        { \" + ', '.join(str(v) for v in row) + \" },\\n\"\n",
    "            result += \"    },\\n\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported tensor dimension: {array.ndim}\")\n",
    "\n",
    "    result += \"};\\n\\n\"\n",
    "    return result\n",
    "\n",
    "def write_c_header(model: torch.nn.Module, header_path: str):\n",
    "    with open(header_path, 'w') as f:\n",
    "        f.write(\"// Auto-generated Q0.7 quantized weights\\n\\n\")\n",
    "        f.write(\"#ifndef Q07_WEIGHTS_H\\n#define Q07_WEIGHTS_H\\n\\n\")\n",
    "        f.write(\"#include <stdint.h>\\n\\n\")\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            q_data = quantize_tensor_q07(param)\n",
    "            c_name = name.replace('.', '_')\n",
    "            f.write(f\"// Shape: {q_data.shape}\\n\")\n",
    "            f.write(format_c_array(c_name, q_data))\n",
    "\n",
    "        f.write(\"#endif // Q07_WEIGHTS_H\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = quantize_tensor_q07(net.fc1.weight)\n",
    "b = quantize_tensor_q07(net.fc1.bias)\n",
    "q2 = quantize_tensor_q07(net.fc2.weight)\n",
    "b2 = quantize_tensor_q07(net.fc2.bias)\n",
    "np.savetxt(\"weights_fc1_q07.txt\", q)\n",
    "np.savetxt(\"bias_fc1_q07.txt\", b)\n",
    "np.savetxt(\"weights_fc2_q07.txt\", q2)\n",
    "np.savetxt(\"bias_fc2_q07.txt\", b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_c_header(net, \"q07_weights.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0\n",
      "Train Set Loss: 2.33\n",
      "Test Set Loss: 2.23\n",
      "Train set accuracy for a single minibatch: 28.00%\n",
      "Test set accuracy for a single minibatch: 29.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 50\n",
      "Train Set Loss: 0.56\n",
      "Test Set Loss: 0.75\n",
      "Train set accuracy for a single minibatch: 89.00%\n",
      "Test set accuracy for a single minibatch: 77.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 100\n",
      "Train Set Loss: 0.49\n",
      "Test Set Loss: 0.55\n",
      "Train set accuracy for a single minibatch: 88.00%\n",
      "Test set accuracy for a single minibatch: 83.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 150\n",
      "Train Set Loss: 0.34\n",
      "Test Set Loss: 0.39\n",
      "Train set accuracy for a single minibatch: 93.00%\n",
      "Test set accuracy for a single minibatch: 86.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 200\n",
      "Train Set Loss: 0.40\n",
      "Test Set Loss: 0.37\n",
      "Train set accuracy for a single minibatch: 89.00%\n",
      "Test set accuracy for a single minibatch: 87.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 250\n",
      "Train Set Loss: 0.42\n",
      "Test Set Loss: 0.19\n",
      "Train set accuracy for a single minibatch: 84.00%\n",
      "Test set accuracy for a single minibatch: 93.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 300\n",
      "Train Set Loss: 0.28\n",
      "Test Set Loss: 0.40\n",
      "Train set accuracy for a single minibatch: 94.00%\n",
      "Test set accuracy for a single minibatch: 88.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 350\n",
      "Train Set Loss: 0.35\n",
      "Test Set Loss: 0.59\n",
      "Train set accuracy for a single minibatch: 95.00%\n",
      "Test set accuracy for a single minibatch: 81.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 400\n",
      "Train Set Loss: 0.24\n",
      "Test Set Loss: 0.33\n",
      "Train set accuracy for a single minibatch: 92.00%\n",
      "Test set accuracy for a single minibatch: 90.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 450\n",
      "Train Set Loss: 0.24\n",
      "Test Set Loss: 0.37\n",
      "Train set accuracy for a single minibatch: 94.00%\n",
      "Test set accuracy for a single minibatch: 90.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 500\n",
      "Train Set Loss: 0.20\n",
      "Test Set Loss: 0.30\n",
      "Train set accuracy for a single minibatch: 93.00%\n",
      "Test set accuracy for a single minibatch: 89.00%\n",
      "\n",
      "\n",
      "Epoch 0, Iteration 550\n",
      "Train Set Loss: 0.52\n",
      "Test Set Loss: 0.48\n",
      "Train set accuracy for a single minibatch: 86.00%\n",
      "Test set accuracy for a single minibatch: 91.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        fc1_out = self.fc1(x)\n",
    "        fc2_out = self.fc2(fc1_out)\n",
    "        return fc2_out\n",
    "\n",
    "ann = ANN().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ann.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output = ann(data.view(batch_size, -1))\n",
    "    _, idx = output.max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    if train:\n",
    "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer():\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "    print_batch_accuracy(data, targets, train=True)\n",
    "    print_batch_accuracy(test_data, test_targets, train=False)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        ann.train()\n",
    "        out = ann(data.view(batch_size, -1))\n",
    "\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        loss_val += loss(out, targets)\n",
    "\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            ann.eval()\n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            out = ann(test_data.view(batch_size, -1))\n",
    "\n",
    "            # Test set loss\n",
    "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "            test_loss += loss(out, test_targets)\n",
    "\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "\n",
    "            # Print train/test loss/accuracy\n",
    "            if counter % 50 == 0:\n",
    "                train_printer()\n",
    "            counter += 1\n",
    "            iter_counter +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correctly classified test set images: 9195/10000\n",
      "Test Set Accuracy: 91.95%\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# drop_last switched to False to keep all samples\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "  ann.eval()\n",
    "  for data, targets in test_loader:\n",
    "    data = data.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    out = ann(data.view(data.size(0), -1))\n",
    "\n",
    "    # calculate total accuracy\n",
    "    _, predicted = out.max(1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets).sum().item()\n",
    "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
    "print(f\"Test Set Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 1.1317e-02, -3.3913e-02, -8.5571e-03,  ...,  6.2682e-03,\n",
       "                        1.3216e-02,  1.6880e-02],\n",
       "                      [ 1.2386e-02,  3.1120e-02, -2.2875e-02,  ..., -2.8876e-02,\n",
       "                        2.7425e-02,  2.4119e-02],\n",
       "                      [-2.4773e-04,  2.7669e-02, -2.6614e-02,  ..., -4.6994e-03,\n",
       "                       -3.4317e-02, -3.2045e-02],\n",
       "                      ...,\n",
       "                      [-3.6028e-03, -3.1044e-02,  2.8029e-02,  ...,  3.0228e-02,\n",
       "                        9.9771e-03,  3.1691e-02],\n",
       "                      [ 3.8209e-03, -6.5553e-03, -2.5519e-02,  ...,  3.2070e-02,\n",
       "                       -7.8906e-03, -1.5710e-02],\n",
       "                      [ 2.7915e-02,  1.9001e-03,  4.1083e-03,  ...,  3.0904e-02,\n",
       "                       -5.5127e-03, -7.2479e-05]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-2.6208e-02, -3.3698e-02,  1.5687e-02,  5.6119e-02,  2.8172e-02,\n",
       "                       6.0481e-02,  5.2268e-02,  5.7457e-02, -3.1140e-02,  3.4086e-02,\n",
       "                       4.3178e-02,  4.5808e-02, -1.0065e-02,  1.1808e-02, -1.5932e-03,\n",
       "                       5.0656e-02, -2.5698e-02, -2.9662e-02, -2.3174e-02, -2.1504e-03,\n",
       "                       3.4613e-02,  8.8811e-03,  4.8451e-02,  6.1346e-02, -7.3468e-04,\n",
       "                       1.0253e-02, -3.2625e-02, -9.5681e-03,  1.3199e-02,  1.5383e-02,\n",
       "                      -9.1945e-03, -2.3979e-02, -5.5228e-02,  5.9490e-03, -7.5405e-05,\n",
       "                       9.9168e-03,  1.2715e-03,  1.8092e-02,  1.5499e-02,  3.1578e-02,\n",
       "                       2.7899e-02, -8.5598e-03, -1.1875e-02, -1.1254e-02,  4.2449e-02,\n",
       "                      -2.7199e-02, -1.7163e-02, -2.5643e-04,  3.8151e-02,  1.6554e-02,\n",
       "                       1.1659e-02, -4.5230e-03, -2.2782e-02, -1.2911e-02,  2.4380e-02,\n",
       "                      -2.9216e-02, -8.1309e-03,  6.0256e-03,  3.7852e-02, -1.5551e-02,\n",
       "                       2.4749e-02,  9.5012e-03,  1.6427e-02, -5.9207e-02, -1.6161e-02,\n",
       "                       1.7819e-02, -8.0222e-03, -6.1397e-03,  7.6729e-03,  3.4901e-02,\n",
       "                      -4.3269e-03,  7.9200e-03,  3.6199e-02, -3.7009e-02,  1.8913e-02,\n",
       "                      -2.0423e-02,  8.0224e-03,  2.3694e-02,  2.4464e-03,  1.5608e-02,\n",
       "                      -5.5501e-03,  3.4370e-02,  2.1568e-02, -5.6680e-03, -6.7229e-03,\n",
       "                      -2.1258e-02, -1.2823e-02,  3.8897e-03, -3.3826e-02,  1.6004e-03,\n",
       "                      -4.9095e-03,  5.5394e-02, -7.6214e-03, -1.7278e-02, -3.3959e-02,\n",
       "                       4.7212e-02,  1.8023e-02,  3.2931e-02,  6.1101e-02,  3.6931e-02,\n",
       "                       8.2510e-03, -4.5626e-03, -1.4316e-02,  2.3226e-03,  1.2389e-02,\n",
       "                       1.4675e-02, -1.6299e-02, -1.2579e-02,  1.3006e-02, -7.3803e-03,\n",
       "                      -4.1518e-02, -2.3473e-02, -3.6330e-03,  1.5538e-02,  1.4754e-02,\n",
       "                       8.5013e-03,  4.0950e-03,  3.0663e-02, -3.6308e-02, -2.1468e-02,\n",
       "                       6.1945e-03,  4.5748e-02, -3.0768e-02, -2.6852e-02,  4.7240e-03,\n",
       "                       1.4617e-02, -2.4334e-02,  4.3183e-02,  3.7625e-02, -4.2197e-02,\n",
       "                      -4.2950e-03, -9.5981e-03, -1.8590e-02,  5.1128e-02, -1.6363e-02,\n",
       "                       2.1993e-02,  6.1942e-02, -7.3303e-03, -2.7472e-02,  7.8213e-03,\n",
       "                       3.0947e-02,  1.9947e-02,  1.1560e-02,  1.0220e-02,  4.9085e-02,\n",
       "                       3.5679e-02,  6.7300e-02,  6.7980e-03,  2.0383e-02, -4.9193e-03,\n",
       "                       4.6198e-03,  4.9178e-02, -5.2279e-02,  4.0725e-02,  1.6732e-02,\n",
       "                       1.0766e-02, -3.1404e-03,  9.3644e-03, -4.5542e-02,  6.3749e-03,\n",
       "                      -1.7393e-02,  4.2978e-02,  5.4974e-02,  1.1496e-02, -1.5605e-03,\n",
       "                      -2.8051e-02,  5.1160e-02,  2.2834e-02,  2.0767e-02,  4.4249e-02,\n",
       "                      -3.5879e-02,  1.0643e-02,  6.6851e-03,  2.3592e-03,  1.2850e-02,\n",
       "                       5.7359e-02, -1.8510e-02, -9.8909e-03, -1.8745e-02,  5.5566e-03,\n",
       "                      -4.2467e-02,  5.4470e-03,  2.7504e-02,  1.0961e-02,  1.5585e-02,\n",
       "                      -3.4850e-03, -2.2993e-02, -3.1881e-02,  9.6831e-03,  4.9563e-02,\n",
       "                      -3.6948e-03, -4.1568e-02,  1.7525e-02,  1.3745e-02, -2.1249e-02,\n",
       "                       2.1284e-03,  1.9137e-02,  2.0760e-02,  6.9178e-03,  1.1036e-02,\n",
       "                       8.0496e-02,  5.2858e-02, -2.5361e-02,  3.0780e-02,  4.9763e-04,\n",
       "                      -1.1518e-02, -1.6797e-03,  6.2015e-02, -9.4375e-03, -7.9426e-04,\n",
       "                       3.0076e-02, -1.8428e-02, -2.2944e-02,  1.1449e-02,  1.7270e-03,\n",
       "                       7.0122e-03,  7.5923e-03, -3.6599e-03,  2.2919e-02, -1.6780e-02,\n",
       "                      -1.7714e-02,  3.3171e-02,  1.3014e-03, -2.3765e-02,  3.3234e-02,\n",
       "                       9.2208e-03,  6.1078e-02,  2.1723e-02,  5.5451e-05,  3.1090e-02,\n",
       "                       5.0039e-03, -3.5017e-03, -1.3697e-02, -4.4640e-03, -2.1579e-02,\n",
       "                       3.9638e-02,  2.5135e-02,  3.4795e-02, -2.7204e-02,  2.8941e-02,\n",
       "                       1.2551e-02, -6.7552e-03,  1.4680e-02,  1.3584e-02,  8.0956e-03,\n",
       "                      -1.6109e-02, -4.5817e-03, -1.5037e-03,  4.2873e-03, -1.0528e-02,\n",
       "                       2.4214e-03,  3.6482e-02,  5.1784e-02, -5.0396e-02, -8.0533e-03,\n",
       "                       4.7996e-02])),\n",
       "             ('lif1.threshold', tensor(1.)),\n",
       "             ('lif1.graded_spikes_factor', tensor(1.)),\n",
       "             ('lif1.reset_mechanism_val', tensor(0)),\n",
       "             ('lif1.beta', tensor(0.9500)),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0654, -0.1137, -0.0557,  ...,  0.0711, -0.0392, -0.0747],\n",
       "                      [-0.0466,  0.0003,  0.1006,  ..., -0.0655, -0.0197,  0.0872],\n",
       "                      [-0.0387, -0.0306,  0.0196,  ...,  0.0267, -0.0381, -0.0755],\n",
       "                      ...,\n",
       "                      [-0.0605, -0.0793, -0.0012,  ..., -0.0178,  0.0719,  0.0338],\n",
       "                      [ 0.0678,  0.1038,  0.0485,  ...,  0.0670, -0.0210, -0.1156],\n",
       "                      [ 0.0321, -0.0046, -0.0635,  ..., -0.0196,  0.0573, -0.0215]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.0652,  0.0043,  0.0325, -0.0484, -0.0378,  0.0038, -0.0382, -0.0096,\n",
       "                       0.0195,  0.0291])),\n",
       "             ('lif2.threshold', tensor(1.)),\n",
       "             ('lif2.graded_spikes_factor', tensor(1.)),\n",
       "             ('lif2.reset_mechanism_val', tensor(0)),\n",
       "             ('lif2.beta', tensor(0.9500))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
